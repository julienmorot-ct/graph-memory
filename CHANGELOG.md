# Changelog

Toutes les modifications notables de ce projet sont document√©es dans ce fichier.

Le format est bas√© sur [Keep a Changelog](https://keepachangelog.com/fr/1.0.0/),
et ce projet adh√®re au [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

---

## [0.6.3] ‚Äî 2026-02-15

### Recherche accent-insensitive + Calibrage seuil RAG

#### Ajout√©
- **Index fulltext Neo4j `standard-folding`** (`graph.py`) ‚Äî Recherche accent-insensitive via un index Lucene avec ASCII folding (√©‚Üíe, √ß‚Üíc, √º‚Üíu). `"r√©versibilit√©"`, `"reversibilite"`, `"REVERSIBILITE"` matchent tous les 3. Lazy init idempotent au premier appel de `search_entities()`.
- **`_search_fulltext()`** ‚Äî Recherche principale via l'index Lucene avec scoring par pertinence, filtr√©e par `memory_id`.
- **`_search_contains()` am√©lior√©** ‚Äî Fallback CONTAINS qui envoie les tokens raw (avec accents) ET normalis√©s (sans accents) √† Neo4j.
- **`_escape_lucene()`** ‚Äî √âchappement des caract√®res sp√©ciaux Lucene (`+`, `-`, `*`, `?`, `~`, etc.).

#### Corrig√©
- **Recherche "r√©versibilit√©" ‚Üí 0 r√©sultats** ‚Äî Python normalisait les accents (`reversibilite`) mais `toLower()` de Neo4j les conservait (`r√©versibilit√©`). D√©salignement corrig√© par l'index fulltext `standard-folding` (principal) + fallback CONTAINS avec double tokens.
- **RAG quasi inactif (seuil 0.65 trop √©lev√©)** ‚Äî BGE-M3 produit des scores cosinus ~0.55-0.63 pour les meilleurs chunks. Le seuil 0.65 √©liminait 93% des chunks pertinents. Abaiss√© √† **0.58** apr√®s benchmark comparatif sur 5 questions √ó 5 seuils (`scripts/test_rag_thresholds.py`).

#### Modifi√©
- **`RAG_SCORE_THRESHOLD` 0.65 ‚Üí 0.58** ‚Äî Calibr√© pour BGE-M3 via benchmark (0.50/0.55/0.58/0.60/0.65 test√©s sur 5 requ√™tes √ó 15 chunks).

#### Refactoris√©
- **`search_entities()`** ‚Äî Strat√©gie en 2 niveaux : fulltext Lucene (scoring) ‚Üí fallback CONTAINS (raw+normalized). 3 nouvelles m√©thodes priv√©es.

#### Fichiers modifi√©s
`graph.py`, `config.py`, `.env.example`, `README.md`

---

## [0.6.2] ‚Äî 2026-02-15

### Interface web graphe am√©lior√©e + Progression CLI

#### Ajout√©
- **Toggle MENTIONS** (üìÑ) ‚Äî Nouveau bouton toggle dans le header du client web pour masquer/afficher les n≈ìuds Document et les ar√™tes MENTIONS. Permet de visualiser uniquement les relations s√©mantiques entre entit√©s (`displayOptions.showMentions` dans `config.js`).
- **Progression CLI avec barres %** ‚Äî L'ingestion en ligne de commande affiche des barres de progression ASCII pour l'extraction LLM (chunk par chunk) et l'embedding (batch par batch), avec compteur d'entit√©s/relations en temps r√©el.

#### Corrig√©
- **Exit isolation automatique avant ASK** ‚Äî Quand l'utilisateur pose une nouvelle question alors que le mode Focus est actif, le graphe repasse automatiquement en vue globale. Plus de filtrage r√©siduel entre deux questions.

#### Fichiers modifi√©s
`config.js`, `graph.html`, `app.js`, `ask.js`, `commands.py`

---

## [0.6.1] ‚Äî 2026-02-15

### Stabilisation ingestion gros documents + Observabilit√©

#### Corrig√©
- **Boucle infinie chunker** (`chunker.py`) ‚Äî `_split_group_with_overlap()` pouvait boucler infiniment quand overlap + prochaine phrase d√©passait `chunk_size` ‚Üí millions de chunks ‚Üí 7.47GB RAM ‚Üí OOM Kill (exit 137). Corrig√© en vidant l'overlap si n√©cessaire.
- **Healthcheck Docker OOM** (`Dockerfile`) ‚Äî Remplac√© `python -c "import httpx; ..."` par `curl` (√©conomise ~50MB RAM par check toutes les 30s).

#### Modifi√©
- **`EXTRACTION_CHUNK_SIZE` r√©duit** (`config.py`) ‚Äî 200K ‚Üí **25K chars** (~6K tokens par chunk). Un document de 135K chars ‚Üí 7 chunks au lieu de 1.

#### Ajout√©
- **Lib√©ration m√©moire proactive** (`server.py`) ‚Äî `del content_base64` + `del content` + `gc.collect()`. Monitoring RSS dans chaque log `[RSS=XXmb]`.
- **Logs chunker d√©taill√©s** (`chunker.py`) ‚Äî 3 passes avec d√©tail section par section (titre, chars, level). `sys.stderr.flush()` syst√©matique.
- **Progression CLI temps r√©el** (`client.py` + `commands.py`) ‚Äî Notifications MCP `ctx.info()` captur√©es c√¥t√© client via monkey-patch `_received_notification`. Rich Live display avec √©tapes + timer.
- **D√©duplication v√©rifi√©e** ‚Äî Deux niveaux : extracteur (`_merge_extraction_results` : par nom+type) + Neo4j (`MERGE` Cypher sur `{name, memory_id}`).

#### Fichiers modifi√©s
`chunker.py`, `Dockerfile`, `config.py`, `server.py`, `client.py`, `commands.py`

---

## [0.6.0] ‚Äî 2026-02-13

### Chunked Graph Extraction + M√©tadonn√©es enrichies

#### Ajout√©
- **Extraction chunked s√©quentielle** (`extractor.py`) ‚Äî Documents longs d√©coup√©s en chunks extraits s√©quentiellement avec contexte cumulatif. Fusion finale avec d√©duplication par (nom, type).
- **M√©tadonn√©es enrichies** ‚Äî N≈ìud Document Neo4j : `source_path`, `source_modified_at`, `size_bytes`, `text_length`, `content_type`.
- **`document_get` optimis√©** ‚Äî Param√®tre `include_content=False` (d√©faut), pas de t√©l√©chargement S3 pour les m√©tadonn√©es.
- **CLI enrichi** ‚Äî `document ingest --source-path`, `document ingest-dir` passent automatiquement les m√©tadonn√©es.
- **Param√®tre** `EXTRACTION_CHUNK_SIZE` (d√©faut 200K chars, configurable via `.env`).
- **Documentation** ‚Äî `DESIGN/chunking_methodology.md`.

#### Modifi√©
- **Timeout LLM** ‚Äî 120s ‚Üí **600s** (gpt-oss:120b chain-of-thought).
- **R√©silience** ‚Äî Si un chunk d'extraction timeout, l'ingestion continue avec les suivants.

#### Fichiers modifi√©s
`extractor.py`, `ontology.py`, `graph.py`, `server.py`, `config.py`, `commands.py`, `shell.py`, `.env.example`

---

## [0.5.2] ‚Äî 2026-02-09

### Q&A ‚Äî Fallback RAG-only + Tokeniser robuste

#### Corrig√©
- **Tokeniser de recherche** (`graph.py`) ‚Äî Ponctuation retir√©e avec `re.findall(r'[a-zA-Z√Ä-√ø]+', ...)`.
- **Normalisation des accents** ‚Äî `unicodedata.normalize('NFKD', ...)` pour matcher `"r√©siliation"` ‚Üî `"RESILIATION"`.

#### Ajout√©
- **Fallback RAG-only** ‚Äî 0 entit√©s graphe ‚Üí recherche Qdrant sur tous les chunks (au lieu de "pas d'infos").
- **Seuil de pertinence RAG** (`RAG_SCORE_THRESHOLD=0.65`).
- **Limite de chunks configurable** (`RAG_CHUNK_LIMIT=8`).
- **Logs d√©cisionnels Q&A** ‚Äî Tokenisation ‚Üí Graphe ‚Üí RAG ‚Üí Contexte LLM.
- **Scores de similarit√©** dans les logs Docker.
- **Stop words enrichis** (~45 mots fran√ßais).
- **Modules RAG** ‚Äî `chunker.py`, `embedder.py`, `vector_store.py`.

#### Modifi√©
- **Qdrant √©pingl√©** `v1.16.2` (au lieu de `latest`).

#### Fichiers modifi√©s
`graph.py`, `server.py`, `config.py`, `docker-compose.yml`, `.env.example`, `chunker.py`, `embedder.py`, `vector_store.py`, `models.py`, `requirements.txt`

---

## [0.5.1] ‚Äî 2026-02-09

### Tokens ‚Äî Champ email + Hash complet

#### Ajout√©
- Champ **email** (optionnel) lors de la cr√©ation de tokens.
- **Hash complet** (SHA256, 64 chars) dans `token list`.
- Colonne **Email** dans les tables CLI + Shell.
- Fichier `VERSION`.
- Documentation CLI (`scripts/README.md`).

#### Fichiers modifi√©s
`models.py`, `token_manager.py`, `server.py`, `display.py`, `commands.py`, `shell.py`

---

## [0.5.0] ‚Äî 2026-02-01

### Version initiale publique

#### Ajout√©
- Extraction d'entit√©s/relations guid√©e par ontologie (LLM).
- Graphe de connaissances Neo4j avec isolation par namespace (multi-tenant).
- Stockage S3 (Dell ECS, AWS, MinIO).
- Interface web interactive (vis-network) avec filtrage avanc√© et panneau ASK.
- CLI compl√®te (Click + Shell interactif avec prompt_toolkit).
- Authentification Bearer Token avec gestion des tokens.
- V√©rification et nettoyage coh√©rence S3/graphe.
- Question/R√©ponse avec citation des documents sources.
- 14 outils MCP expos√©s via HTTP/SSE.
- Support des formats : PDF, DOCX, Markdown, TXT, HTML, CSV.
- 4 ontologies : legal, cloud, managed-services, technical.
